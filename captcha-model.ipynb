{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852041eb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa49c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 11:19:08.697464: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a091d29",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b11b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(\"/Users/alertrack/Documents/Captcha-Bot/dataset/archive\"):\n",
    "    for filename in filenames:        \n",
    "        filelist.append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de08c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "for image_path in filelist:\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = image / 255  # Normalização\n",
    "    \n",
    "    resized_image = cv2.resize(image, (150, 40))\n",
    "    \n",
    "    reshaped_image = np.expand_dims(resized_image, axis=-1)\n",
    "    \n",
    "    images.append(reshaped_image)\n",
    "    \n",
    "    image_label = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    labels.append(image_label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f489c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[19])\n",
    "plt.title(labels[19])\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "print(images[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ee14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot Encoding List of 5 character strings\n",
    "def one_hot_encode(characters, char_pool):\n",
    "    char_to_index = {char: i for i, char in enumerate(char_pool)}\n",
    "    num_classes = len(char_pool)\n",
    "    encoding_size = len(characters[0])\n",
    "    \n",
    "    one_hot_encoded = np.zeros((len(characters), encoding_size, num_classes), dtype=int)\n",
    "\n",
    "    for i, word in enumerate(characters):\n",
    "        for j, char in enumerate(word):\n",
    "            index = char_to_index[char]\n",
    "            one_hot_encoded[i, j, index] = 1\n",
    "\n",
    "    return one_hot_encoded\n",
    "\n",
    "char_pool = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Labels\n",
    "encoded_labels = one_hot_encode(labels, char_pool)\n",
    "encoded_labels = np.array(encoded_labels)\n",
    "encoded_labels.shape, encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling Array\n",
    "indices = np.random.permutation(len(labels))\n",
    "\n",
    "images = images[indices]\n",
    "encoded_labels = encoded_labels[indices]\n",
    "\n",
    "images.shape, encoded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514039ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Validation Split\n",
    "split_index = int(len(labels) * 0.9)\n",
    "\n",
    "train_labels = encoded_labels[:split_index]\n",
    "val_labels = encoded_labels[split_index:]\n",
    "\n",
    "train_images = images[:split_index]\n",
    "val_images = images[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5023e8-b0d8-4ef9-990b-4fbd25623618",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.)\n",
    "train_generator = train_datagen.flow(np.array(train_images), np.array(train_labels), batch_size=batch_size)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.)\n",
    "val_generator = val_datagen.flow(np.array(val_images), np.array(val_labels), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc4e80",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0de534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(40, 150, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c589648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec11ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense Layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(5 * 62, activation='softmax'))\n",
    "model.add(layers.Reshape((5, 62)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa417255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8ef47",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2167d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=30, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history.history['loss']\n",
    "val_loss_values = history.history['val_loss']\n",
    "\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
